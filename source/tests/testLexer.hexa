// The Hexa Compiler
// Copyright (C) 2021-2023 Oleh Petrenko
// Copyright (C) 2018 Bogdan Danylchenko
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, version 3 of the License.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

class TestLexer {
	static fun test() {
		console.log("TestLexer begin")

		// Shebang
		compare("#!/bin", [], [])
		compare("#!/bin\n", [], [])
		compare("#!/bin\n//", [], [])
		compare("#!/bin\r\n123", [Token.Integer], ["123"]) // May not work on Linux because of \r if no `bin\r` file exist
		compare("#!/bin\n\r123", [Token.Integer], ["123"]) // \r is completely ignored by lexer
		compare("#!/bin\n123", [Token.Integer], ["123"])

		// Empty (whitespace, comments)
		compare("", [], [])
		compare("\n", [], [])
		compare("\n\n", [], [])
		compare("\r\r\n\r\n\r\t", [], [])
		compare(" ", [], [])
		compare("  ", [], [])
		compare("	", [], [])
		compare("		", [], [])
		compare("	 	", [], [])
		compare("/* */", [], [])
		compare("/*\n*/", [], [])
		compare("//", [], [])
		compare("// ", [], [])
		compare("//\n", [], [])

		// Int
		compare("123", [Token.Integer], ["123"])
		compare(" 0 ", [Token.Integer], ["0"])
		compare("0", [Token.Integer], ["0"])
		compare("1 2 3", [Token.Integer, Token.Integer, Token.Integer], ["1", "2", "3"])
		compare("0x1", [Token.Integer], ["0x1"])
		compare("0x0", [Token.Integer], ["0x0"])
		compare("0xF", [Token.Integer], ["0xF"])
		compare("0xFA", [Token.Integer], ["0xFA"])
		compare("0xFABCDEF", [Token.Integer], ["0xFABCDEF"])
		compare("0x1F2A3B4C5D6E7F0", [Token.Integer], ["0x1F2A3B4C5D6E7F0"])
		compare("-123", [Token.Subtract, Token.Integer], ["-", "123"])
		compare("+123", [Token.Add, Token.Integer], ["+", "123"])

		// Float
		compare("0.123", [Token.FloatingPoint], ["0.123"])
		compare("0.0", [Token.FloatingPoint], ["0.0"])
		compare("0.0e+1", [Token.FloatingPoint], ["0.0e+1"])
		compare("0.0E-1", [Token.FloatingPoint], ["0.0E-1"])
		compare("0E-123", [Token.FloatingPoint], ["0E-123"])
		compare("123e123", [Token.FloatingPoint], ["123e123"])
		compare("1 2.0 3", [Token.Integer, Token.FloatingPoint, Token.Integer], ["1", "2.0", "3"])

		// String
		compare("'s'", [Token.QuotedString], ["'s'"])
		compare('"s"', [Token.QuotedString], ["'s'"]) // TODO Quotes `"` and `'` should be differentiated for pretty printing
		compare("\"s\"", [Token.QuotedString], ["'s'"]) // TODO All `\*` should be kept for pretty printing
		compare("`s`", [Token.Backtick], ["`s`"])
		compare("`aaa bbb``ccc` `ddd`", [Token.Backtick, Token.Backtick], ["`aaa bbbccc`", "`ddd`"])
		compare("````````", [Token.Backtick], ["``"])
		compare("``", [Token.Backtick], ["``"])
		compare("``\n", [Token.Backtick], ["``"])
		compare("``\n``", [Token.Backtick, Token.Backtick], ["``", "``"])

		// String consistency - repair \r\n to \n for non-raw ones
		compare("'s\n'", [Token.QuotedString], ["'s\n'"]) // '
		compare("'s\r\n'", [Token.QuotedString], ["'s\n'"]) // '
		compare("'s
			s'", [Token.QuotedString], ["'s\n\t\t\ts'"]) // Test on actual code
		compare('"s\n"', [Token.QuotedString], ["'s\n'"]) // "
		compare('"s\r\n"', [Token.QuotedString], ["'s\n'"]) // "
		compare('"\r\ns\r\n"', [Token.QuotedString], ["'\ns\n'"]) // "
		compare("`s\n`", [Token.Backtick], ["`s\n`"]) // `
		compare("`s\r\n`", [Token.Backtick], ["`s\n`"]) // `
		compare("`s\r`", [Token.Backtick], ["`s\r`"]) // `
		compare("`s\\r`", [Token.Backtick], ["`s\\r`"]) // `

		// Identifiers
		compare("T", [Token.Title], ["T"])
		compare("T val", [Token.Title, Token.Identifier], ["T", "val"])
		compare("T val Type", [Token.Title, Token.Identifier, Token.Title], ["T", "val", "Type"])
		compare("_T", [Token.Identifier], ["_T"])
		compare("v", [Token.Identifier], ["v"])
		compare("_v", [Token.Identifier], ["_v"])
		compare("_123", [Token.Identifier], ["_123"])

		// Multichar tokens
		compare(" } ", [Token.BlockClose], ["}"])
		compare("==", [Token.Equal], ["=="])
		compare("===", [Token.Equal, Token.Assign], ["==", "="])
		compare("== =", [Token.Equal, Token.Assign], ["==", "="])
		compare("= ==", [Token.Assign, Token.Equal], ["=", "=="])
		compare("=====", [Token.Equal, Token.Equal, Token.Assign], ["==", "==", "="])
		compare(
			"> >> >>> . .. ...",
			[Token.Greater, Token.BitwiseRightShift, Token.UnsignedRightShift, Token.Dot, Token.Dot, Token.Dot, Token.Interval],
			[">", ">>", ">>>", ".", ".", ".", "..."]
		)
		compare(
			">>>>>>.......",
			[Token.UnsignedRightShift, Token.UnsignedRightShift, Token.Interval, Token.Interval, Token.Dot],
			[">>>", ">>>", "...", "...", "."]
		)

		// Position of tokens

		// Position of errors

		console.log("TestLexer done \(Math.round((passed/overall)*100))% (\(passed)/\(overall))")
	}

	static var passed = 0
	static var overall = 0

	/// Fix invisible chars like \t\r\n
	static fun renderInvisibleChars(input: String): String {
		return input
		.split('\r').join('\\r')
		.split('\n').join('\\n')
		.split('\t').join('\\t')
	}

	/// Token and value equality
	static fun compare(
		input: String,
		expect: [Token],
		expectValue: [String],
		expectColumn: [Int] = null,
		expectLine: [Int] = null
	): Void {
		expect.push(Token.Eof)
		let output = Lexer.tokenize(Buffer.from(input), "TEST")
		var pos = 0

		fun incorrect(text: String) {
			var got = Token.stringify(output.token[pos] as! Token, output.value[pos])
			got = renderInvisibleChars(got)
			console.log('Incorrect token `\(got)` in string `\(renderInvisibleChars(input))` at index \(pos)')
			console.log(text)
			throw 'TestLexer test fail: `\(input)` did throw exception.'
		}

		overall++
		for ex in expect {
			if ex == Token.Eof {
				break
			}

			if ex != output.token[pos] as! Token {
				incorrect('Expected `\(renderInvisibleChars(Token.stringify(ex)))`')
				return
			}

			let value = Token.stringify(output.token[pos] as! Token, output.value[pos])
			if expectValue[pos] != value {
				incorrect('Expected value `\(renderInvisibleChars(expectValue[pos]))` but got `\(renderInvisibleChars(value))`')
				return
			}

			pos++
		}
		passed++
	}
}
